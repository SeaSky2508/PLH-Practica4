{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/marcel/.local/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (0.14.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.2)\n",
      "Requirement already satisfied: aiohttp in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: packaging in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: xxhash in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/marcel/.local/lib/python3.10/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/marcel/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/marcel/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /usr/lib/python3/dist-packages (from responses<0.19->datasets) (1.26.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/marcel/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (3.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset catalan_general_crawling (/home/marcel/.cache/huggingface/datasets/projecte-aina___catalan_general_crawling/default/1.0.0/fb8a4dbf3849d7aad584ad030c058c67c6a935ee7b8d6e37411514da9376a2fb)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "Found cached dataset sts-ca (/home/marcel/.cache/huggingface/datasets/projecte-aina___sts-ca/StsCa/1.0.2/bad37fb7fb0f06f3d2316e29637293b25160a93a24f36f1974f21313ac2f3342)\n",
      "100%|██████████| 3/3 [00:00<00:00, 175.53it/s]\n",
      "Found cached dataset tecla (/home/marcel/.cache/huggingface/datasets/projecte-aina___tecla/tecla/1.0.1/a0d9e053f5ad640d0203e50ca4cc4e254bdb7ff825b2ed4d4abc1ca640498ec6)\n",
      "100%|██████████| 3/3 [00:00<00:00, 18.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Datasets Provided load - when run the first time takes longer than next times\n",
    "cat_gen_crawling = load_dataset(\"projecte-aina/catalan_general_crawling\")\n",
    "text_similarity = load_dataset(\"projecte-aina/sts-ca\")\n",
    "text_classification = load_dataset(\"projecte-aina/tecla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1016113\n",
      "    })\n",
      "})\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 2073\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 500\n",
      "    })\n",
      "})\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label1', 'label2'],\n",
      "        num_rows: 90700\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label1', 'label2'],\n",
      "        num_rows: 5669\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label1', 'label2'],\n",
      "        num_rows: 17007\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "'Each of them is a dictionary where each element is an object of class dataset.'\n",
    "'Objects of class dataset are used like a dictionary to access its data as shown in examples.'\n",
    "print(cat_gen_crawling) # Ex: text -> cat_gen_crawling['train']['text']\n",
    "print()\n",
    "print(text_similarity)\n",
    "print()\n",
    "print(text_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_DATASET_REFS',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_build_local_temp_path',\n",
       " '_check_index_is_initialized',\n",
       " '_data',\n",
       " '_estimate_nbytes',\n",
       " '_fingerprint',\n",
       " '_format_columns',\n",
       " '_format_kwargs',\n",
       " '_format_type',\n",
       " '_generate_examples_from_shards',\n",
       " '_get_cache_file_path',\n",
       " '_get_output_signature',\n",
       " '_getitem',\n",
       " '_indexes',\n",
       " '_indices',\n",
       " '_info',\n",
       " '_map_single',\n",
       " '_new_dataset_with_indices',\n",
       " '_output_all_columns',\n",
       " '_push_parquet_shards_to_hub',\n",
       " '_save_to_disk_single',\n",
       " '_select_contiguous',\n",
       " '_select_with_indices_mapping',\n",
       " '_split',\n",
       " 'add_column',\n",
       " 'add_elasticsearch_index',\n",
       " 'add_faiss_index',\n",
       " 'add_faiss_index_from_external_arrays',\n",
       " 'add_item',\n",
       " 'align_labels_with_mapping',\n",
       " 'builder_name',\n",
       " 'cache_files',\n",
       " 'cast',\n",
       " 'cast_column',\n",
       " 'citation',\n",
       " 'class_encode_column',\n",
       " 'cleanup_cache_files',\n",
       " 'column_names',\n",
       " 'config_name',\n",
       " 'data',\n",
       " 'dataset_size',\n",
       " 'description',\n",
       " 'download_checksums',\n",
       " 'download_size',\n",
       " 'drop_index',\n",
       " 'export',\n",
       " 'features',\n",
       " 'filter',\n",
       " 'flatten',\n",
       " 'flatten_indices',\n",
       " 'format',\n",
       " 'formatted_as',\n",
       " 'from_buffer',\n",
       " 'from_csv',\n",
       " 'from_dict',\n",
       " 'from_file',\n",
       " 'from_generator',\n",
       " 'from_json',\n",
       " 'from_list',\n",
       " 'from_pandas',\n",
       " 'from_parquet',\n",
       " 'from_spark',\n",
       " 'from_sql',\n",
       " 'from_text',\n",
       " 'get_index',\n",
       " 'get_nearest_examples',\n",
       " 'get_nearest_examples_batch',\n",
       " 'homepage',\n",
       " 'info',\n",
       " 'is_index_initialized',\n",
       " 'iter',\n",
       " 'license',\n",
       " 'list_indexes',\n",
       " 'load_elasticsearch_index',\n",
       " 'load_faiss_index',\n",
       " 'load_from_disk',\n",
       " 'map',\n",
       " 'num_columns',\n",
       " 'num_rows',\n",
       " 'prepare_for_task',\n",
       " 'push_to_hub',\n",
       " 'remove_columns',\n",
       " 'rename_column',\n",
       " 'rename_columns',\n",
       " 'reset_format',\n",
       " 'save_faiss_index',\n",
       " 'save_to_disk',\n",
       " 'search',\n",
       " 'search_batch',\n",
       " 'select',\n",
       " 'select_columns',\n",
       " 'set_format',\n",
       " 'set_transform',\n",
       " 'shape',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'size_in_bytes',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'supervised_keys',\n",
       " 'task_templates',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_iterable_dataset',\n",
       " 'to_json',\n",
       " 'to_list',\n",
       " 'to_pandas',\n",
       " 'to_parquet',\n",
       " 'to_sql',\n",
       " 'to_tf_dataset',\n",
       " 'train_test_split',\n",
       " 'unique',\n",
       " 'version',\n",
       " 'with_format',\n",
       " 'with_transform']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Further inspection of the methods of a Dataset object\n",
    "# If we search we can see a method called to_pandas which seems pretty interesting...\n",
    "dir(cat_gen_crawling['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reduïu els costos dels processos administratiu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>En compliment de la Directiva 2009/136/CE, des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L'ús de la informació continguda en aquest llo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Els Reconeixements Administració Oberta als aj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>En el marc del desenvolupament de l'Administra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016108</th>\n",
       "      <td>L'alumnat de llatí i grec de 1r i 2n BATX van ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016109</th>\n",
       "      <td>El dimecres 14 de febrer vam rebre al nostre c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016110</th>\n",
       "      <td>El dimecres dia 7 l'alumnat de 2n de Batxiller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016111</th>\n",
       "      <td>E l nostre Centre des de fa molts anys partici...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016112</th>\n",
       "      <td>El passat 26 de setembre vam celebrar el Dia E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1016113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "0        Reduïu els costos dels processos administratiu...\n",
       "1        En compliment de la Directiva 2009/136/CE, des...\n",
       "2        L'ús de la informació continguda en aquest llo...\n",
       "3        Els Reconeixements Administració Oberta als aj...\n",
       "4        En el marc del desenvolupament de l'Administra...\n",
       "...                                                    ...\n",
       "1016108  L'alumnat de llatí i grec de 1r i 2n BATX van ...\n",
       "1016109  El dimecres 14 de febrer vam rebre al nostre c...\n",
       "1016110  El dimecres dia 7 l'alumnat de 2n de Batxiller...\n",
       "1016111  E l nostre Centre des de fa molts anys partici...\n",
       "1016112  El passat 26 de setembre vam celebrar el Dia E...\n",
       "\n",
       "[1016113 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_gen_crawling['train'].to_pandas() # We can get the data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_models import Model\n",
    "from class_datasets import Data\n",
    "'...'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
